#!/usr/bin/env python3
"""
ContentFlowè‡ªå‹•ç”»åƒç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  - Stable Diffusionå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Phase A: SDå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆæœ€é©åŒ–ç‰ˆ

Usage:
    python auto-sd-generator.py --config prompts.json --output /path/to/output
"""

import os
import sys
import json
import argparse
import torch
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
from diffusers import StableDiffusionXLPipeline

# è¨­å®šå®šæ•°
MODEL_PATH = "/Users/gotohiro/Documents/user/Products/AI/models/diffusers/juggernaut-xl"
PYTHON_ENV = "/Users/gotohiro/Documents/user/Products/stable-diffusion-local/venv310/bin/python"

# ContentFlowæœ€é©åŒ–è¨­å®š
CONTENTFLOW_SETTINGS = {
    "width": 1600,
    "height": 896,  # 16:9æ¯”ç‡ã€8ã®å€æ•°
    "num_inference_steps": 25,
    "guidance_scale": 7.5,
    "torch_dtype": torch.float16,
    "use_safetensors": False,  # .binå½¢å¼ã®ãŸã‚å¿…é ˆ
    "device": "mps"  # Apple Siliconæœ€é©åŒ–
}

# è»½é‡ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰è¨­å®š
LIGHT_TEST_SETTINGS = {
    "width": 512,
    "height": 512,  # é«˜é€ŸåŒ–ã®ãŸã‚å°ã•ã„ã‚µã‚¤ã‚º
    "num_inference_steps": 10,  # é«˜é€ŸåŒ–ã®ãŸã‚å°‘ãªã„ã‚¹ãƒ†ãƒƒãƒ—
    "guidance_scale": 7.5,
    "torch_dtype": torch.float16,
    "use_safetensors": False,
    "device": "mps"
}

class ContentFlowSDGenerator:
    """ContentFlowç”¨Stable Diffusionç”»åƒç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model_path: str = MODEL_PATH, test_mode: bool = False):
        self.model_path = model_path
        self.pipe = None
        self.test_mode = test_mode
        self.settings = LIGHT_TEST_SETTINGS if test_mode else CONTENTFLOW_SETTINGS
        self.generation_stats = {
            "total_images": 0,
            "successful_generations": 0,
            "failed_generations": 0,
            "total_time": 0
        }
    
    def initialize_pipeline(self) -> bool:
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–"""
        try:
            print("ğŸ“¦ Stable Diffusion ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ä¸­...")
            print(f"ğŸ¯ ãƒ¢ãƒ‡ãƒ«: {self.model_path}")
            
            # ãƒ¢ãƒ‡ãƒ«å­˜åœ¨ç¢ºèª
            if not os.path.exists(self.model_path):
                print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.model_path}")
                return False
            
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
            self.pipe = StableDiffusionXLPipeline.from_pretrained(
                self.model_path,
                torch_dtype=self.settings["torch_dtype"],
                use_safetensors=self.settings["use_safetensors"]
            ).to(self.settings["device"])
            
            print("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def validate_prompt_config(self, config: Dict[str, Any]) -> bool:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®šã®æ¤œè¨¼"""
        required_fields = ["prompts", "article_info"]
        
        for field in required_fields:
            if field not in config:
                print(f"âŒ å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³: {field}")
                return False
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé…åˆ—ã®æ¤œè¨¼
        if not isinstance(config["prompts"], list) or len(config["prompts"]) == 0:
            print("âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé…åˆ—ãŒç„¡åŠ¹ã§ã™")
            return False
        
        # å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç¢ºèª
        for i, prompt in enumerate(config["prompts"]):
            required_prompt_fields = ["name", "prompt", "filename_prefix"]
            for field in required_prompt_fields:
                if field not in prompt:
                    print(f"âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ{i+1}ã«å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³: {field}")
                    return False
        
        return True
    
    def generate_single_image(self, prompt_config: Dict[str, str], output_dir: Path, variations: int = 1) -> List[str]:
        """å˜ä¸€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ç”»åƒç”Ÿæˆ"""
        generated_files = []
        
        try:
            prompt = prompt_config["prompt"]
            negative_prompt = prompt_config.get("negative_prompt", "")
            filename_prefix = prompt_config["filename_prefix"]
            name = prompt_config["name"]
            
            print(f"ğŸ¨ {name} ç”»åƒç”Ÿæˆé–‹å§‹...")
            print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt[:100]}...")
            
            for i in range(variations):
                start_time = datetime.now()
                
                # ç”»åƒç”Ÿæˆ
                image = self.pipe(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    width=self.settings["width"],
                    height=self.settings["height"],
                    num_inference_steps=self.settings["num_inference_steps"],
                    guidance_scale=self.settings["guidance_scale"]
                ).images[0]
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{filename_prefix}-{i+1:03d}-{timestamp}.png"
                filepath = output_dir / filename
                
                # ç”»åƒä¿å­˜
                image.save(filepath)
                generated_files.append(str(filepath))
                
                # çµ±è¨ˆæ›´æ–°
                generation_time = (datetime.now() - start_time).total_seconds()
                self.generation_stats["total_time"] += generation_time
                self.generation_stats["successful_generations"] += 1
                
                print(f"âœ… {filename} ç”Ÿæˆå®Œäº† ({generation_time:.1f}ç§’)")
            
            return generated_files
            
        except Exception as e:
            print(f"âŒ ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼ ({name}): {e}")
            self.generation_stats["failed_generations"] += 1
            return []
    
    def generate_batch_images(self, config_path: str, output_dir: str, variations: int = 1) -> Dict[str, Any]:
        """ãƒãƒƒãƒç”»åƒç”Ÿæˆãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        try:
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            print(f"ğŸ“„ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {config_path}")
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # è¨­å®šæ¤œè¨¼
            if not self.validate_prompt_config(config):
                return {"success": False, "error": "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒç„¡åŠ¹ã§ã™"}
            
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_path}")
            
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
            if not self.initialize_pipeline():
                return {"success": False, "error": "ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ"}
            
            # è¨˜äº‹æƒ…å ±è¡¨ç¤º
            article_info = config["article_info"]
            print(f"ğŸ¯ è¨˜äº‹: {article_info['title']}")
            print(f"ğŸ¨ ã‚¹ã‚¿ã‚¤ãƒ«: {article_info['style']}")
            print(f"ğŸ“Š ç”Ÿæˆäºˆå®š: {len(config['prompts'])}ã‚·ãƒ¼ãƒ³ Ã— {variations}ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³")
            
            # ãƒãƒƒãƒç”Ÿæˆé–‹å§‹
            start_time = datetime.now()
            all_generated_files = {}
            
            for prompt_config in config["prompts"]:
                name = prompt_config["name"]
                generated_files = self.generate_single_image(prompt_config, output_path, variations)
                all_generated_files[name] = generated_files
                self.generation_stats["total_images"] += len(generated_files)
                
                # é€²è¡ŒçŠ¶æ³è¡¨ç¤º
                print(f"ğŸ“ˆ é€²è¡ŒçŠ¶æ³: {self.generation_stats['successful_generations']}/{len(config['prompts']) * variations}")
            
            # å®Œäº†çµ±è¨ˆ
            total_time = (datetime.now() - start_time).total_seconds()
            self.generation_stats["total_time"] = total_time
            
            print("\nğŸ‰ ãƒãƒƒãƒç”»åƒç”Ÿæˆå®Œäº†!")
            print(f"ğŸ“Š çµ±è¨ˆ:")
            print(f"  - ç·ç”»åƒæ•°: {self.generation_stats['total_images']}")
            print(f"  - æˆåŠŸ: {self.generation_stats['successful_generations']}")
            print(f"  - å¤±æ•—: {self.generation_stats['failed_generations']}")
            print(f"  - ç·æ™‚é–“: {total_time:.1f}ç§’")
            print(f"  - å¹³å‡æ™‚é–“/æš: {total_time/max(1, self.generation_stats['successful_generations']):.1f}ç§’")
            
            return {
                "success": True,
                "generated_files": all_generated_files,
                "stats": self.generation_stats,
                "article_info": article_info
            }
            
        except Exception as e:
            print(f"âŒ ãƒãƒƒãƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"success": False, "error": str(e)}

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description='ContentFlowè‡ªå‹•ç”»åƒç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ')
    parser.add_argument('--config', required=True, help='ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®šJSONãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--output', required=True, help='ç”»åƒå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--variations', type=int, default=1, help='å„ã‚·ãƒ¼ãƒ³ã®ç”Ÿæˆãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1ï¼‰')
    parser.add_argument('--test', action='store_true', help='ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆ1æšã®ã¿ç”Ÿæˆï¼‰')
    
    args = parser.parse_args()
    
    print("ğŸš€ ContentFlowè‡ªå‹•ç”»åƒç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰
    if args.test:
        print("ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: æœ€åˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ç”Ÿæˆ")
        args.variations = 1
    
    # ç”Ÿæˆå®Ÿè¡Œ
    generator = ContentFlowSDGenerator(test_mode=args.test)
    result = generator.generate_batch_images(args.config, args.output, args.variations)
    
    if result["success"]:
        print("\nâœ… å…¨å‡¦ç†å®Œäº†")
        # çµæœã‚’JSONã§ä¿å­˜
        result_file = Path(args.output) / "generation_result.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“„ çµæœä¿å­˜: {result_file}")
    else:
        print(f"\nâŒ å‡¦ç†å¤±æ•—: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
        sys.exit(1)

if __name__ == "__main__":
    main()